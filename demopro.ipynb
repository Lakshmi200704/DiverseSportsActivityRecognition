{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f6eebe5-1dd4-46e9-a053-be8ccacec07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_frames(video_path, output_dir, fps=5):\n",
    "    \"\"\"\n",
    "    Extract frames from a video and save them as images.\n",
    "    Args:\n",
    "    - video_path (str): Path to the video file.\n",
    "    - output_dir (str): Directory to save the frames.\n",
    "    - fps (int): Number of frames per second to extract.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir) \n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval = int(video_fps / fps)\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % interval == 0:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "        frame_count += 1\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3fde0c9-6779-4603-b3cf-21f5107ae373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting frames ---> ./ucf_sports_actions/ucf action\n",
      "extracted frames ---> ./ucf_sports_actions/ucf action\n",
      "\n",
      "extracting frames ---> ./ucf_sports_actions_test/ucf action\n",
      "extracted frames ---> ./ucf_sports_actions_test/ucf action\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_videos_and_run_extract_frames(base_path, label_map):\n",
    "    for class_label, class_name in label_map.items():\n",
    "        class_folder = f'{base_path}/{class_name}'\n",
    "        \n",
    "        if not os.path.exists(class_folder):\n",
    "            print(f\"Folder does not exist: {class_folder}\\n\")  # Print if the folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        # Loop through each subfolder\n",
    "        subfolders = os.listdir(class_folder)\n",
    "        \n",
    "        if '.DS_Store' in subfolders:\n",
    "            subfolders.remove('.DS_Store')\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            # print(f'{class_folder}/{subfolder}')\n",
    "            for image_file in os.listdir(f'{class_folder}/{subfolder}'):\n",
    "                if '.avi' in f'{class_folder}/{subfolder}/{image_file}':\n",
    "                    extract_frames(f'{class_folder}/{subfolder}/{image_file}', f'{class_folder}/{subfolder}/output_frames/', fps=9)\n",
    "\n",
    "# Define your label map based on your class names\n",
    "label_map = {\n",
    "    0: \"Diving-Side\", 1: \"Golf-Swing-Back\", 2: \"Golf-Swing-Front\", \n",
    "    3: \"Golf-Swing-Side\", 4: \"Kicking-Front\", 5: \"Kicking-Side\",\n",
    "    6: \"Lifting\", 7: \"Riding-Horse\", 8: \"Run-Side\", \n",
    "    9: \"SkateBoarding-Front\", 10: \"Swing-Bench\", 11: \"Walk-Front\"\n",
    "}\n",
    "\n",
    "# Load image data\n",
    "print(\"extracting frames ---> ./ucf_sports_actions/ucf action\")\n",
    "find_videos_and_run_extract_frames(\"./ucf_sports_actions/ucf action\", label_map)\n",
    "print(\"extracted frames ---> ./ucf_sports_actions/ucf action\\n\")\n",
    "print(\"extracting frames ---> ./ucf_sports_actions_test/ucf action\")\n",
    "find_videos_and_run_extract_frames(\"./ucf_sports_actions_test/ucf action\", label_map)\n",
    "print(\"extracted frames ---> ./ucf_sports_actions_test/ucf action\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6c737f-a7e7-47e7-8029-5c059b45cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ActionRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ActionRecognitionModel, self).__init__()\n",
    "        \n",
    "        # Pretrained 2D CNN (ResNet) for feature extraction\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "        # 3D Convolution Layer\n",
    "        self.conv3d = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), stride=1, padding=1)\n",
    "        \n",
    "        # LSTM for Temporal Dynamics\n",
    "        self.lstm = nn.LSTM(2048, 512, batch_first=True)\n",
    "        \n",
    "        # Fully Connected Layer for classification\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, c, h, w = x.size()  # Expecting 4 dimensions from DataLoader\n",
    "        x = x.unsqueeze(1)  # Add time step dimension, making it (batch_size, time_steps, c, h, w)\n",
    "        batch_size, time_steps, c, h, w = x.size()\n",
    "        \n",
    "        cnn_out = []\n",
    "        \n",
    "        # Apply CNN to each frame\n",
    "        for t in range(time_steps):\n",
    "            frame_features = self.feature_extractor(x[:, t, :, :, :])  # Output shape: (batch_size, 2048, H', W')\n",
    "            \n",
    "            # Apply adaptive average pooling to reduce (2048, H', W') to (2048, 1, 1)\n",
    "            frame_features = torch.nn.functional.adaptive_avg_pool2d(frame_features, (1, 1))\n",
    "            \n",
    "            # Flatten to get (batch_size, 2048)\n",
    "            frame_features = frame_features.view(batch_size, 2048)\n",
    "            cnn_out.append(frame_features)\n",
    "        \n",
    "        cnn_out = torch.stack(cnn_out, dim=1)  # Shape: (batch_size, time_steps, 2048)\n",
    "        \n",
    "        # LSTM for sequence processing\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        \n",
    "        # Classification layer\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = ActionRecognitionModel(num_classes=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfd0074b-be6d-4639-855e-9d87bc673f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device ===========> cuda\n",
      "Training Dataset Size: 8185\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device ===========> {device}')\n",
    "# Move the model to the appropriate device\n",
    "\n",
    "# Custom function to pad images to a target size\n",
    "def pad_tensor(image, target_size):\n",
    "    # Convert image to tensor first if not already done\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    \n",
    "    # Padding: pad (width, height) to match the target size\n",
    "    padded_tensor = F.pad(tensor, \n",
    "                            (0, target_size[2] - tensor.size(2),  # pad width\n",
    "                            0, target_size[1] - tensor.size(1)))  # pad height\n",
    "    return padded_tensor\n",
    "\n",
    "# Custom transform to resize or pad images to the target size\n",
    "class ResizeOrPadTransform:\n",
    "    def __init__(self, target_size):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        # Pad image to target size\n",
    "        return pad_tensor(image, self.target_size)\n",
    "\n",
    "# Set your desired target size (C, H, W) - example target size (3, 404, 720)\n",
    "target_size = (3, 404, 720)\n",
    "\n",
    "# Use the custom transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    ResizeOrPadTransform(target_size)  # Apply padding to match target size\n",
    "])\n",
    "# Prepare data\n",
    "train_dataset = ImageFolder('./ucf_sports_actions/ucf action/', transform=transform)\n",
    "# Now you can create DataLoaders for both datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# Print dataset sizes\n",
    "print(f\"Training Dataset Size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09cf868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device ===========> cuda\n",
      "Epoch [1/10], Loss: 0.0045\n",
      "Epoch [2/10], Loss: 0.0023\n",
      "Epoch [3/10], Loss: 0.0018\n",
      "Epoch [4/10], Loss: 0.0021\n",
      "Epoch [5/10], Loss: 0.0008\n",
      "Epoch [6/10], Loss: 0.0004\n",
      "Epoch [7/10], Loss: 0.0005\n",
      "Epoch [8/10], Loss: 0.0023\n",
      "Epoch [9/10], Loss: 0.0005\n",
      "Epoch [10/10], Loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "print(f'device ===========> {device}')\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "trained_model = model.to(device)\n",
    "trained_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = trained_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b562ffc-ef5c-4886-9f4e-a81a830d3512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Size: 1456\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageFolder('./ucf_sports_actions_test/ucf action/', transform=transform)\n",
    "print(f\"Test Dataset Size: {len(test_dataset)}\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0e31c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.11%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a model on a given dataset (data_loader).\n",
    "    \n",
    "    Args:\n",
    "    - model: The PyTorch model to evaluate.\n",
    "    - data_loader: The DataLoader containing the dataset.\n",
    "    - device: The device to perform calculations on (CPU or GPU).\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy (float): The accuracy of the model on the given dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "            \n",
    "            total += labels.size(0)  # Increment total count\n",
    "            correct += (predicted == labels).sum().item()  # Increment correct count\n",
    "    \n",
    "    accuracy = 100 * correct / total  # Calculate accuracy as percentage\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = calculate_accuracy(trained_model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "776ff2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravit\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_precision(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate the precision of a model on a given dataset (data_loader).\n",
    "    \n",
    "    Args:\n",
    "    - model: The PyTorch model to evaluate.\n",
    "    - data_loader: The DataLoader containing the dataset.\n",
    "    - device: The device to perform calculations on (CPU or GPU).\n",
    "    \n",
    "    Returns:\n",
    "    - precision (float): The precision of the model on the given dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "            \n",
    "            # Store labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate precision using sklearn's precision_score function\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')  # 'weighted' handles class imbalance\n",
    "    return precision\n",
    "# Example usage after training or during evaluation\n",
    "test_precision = calculate_precision(trained_model, test_loader, device)\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1412ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall: 0.8111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def calculate_recall(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate the recall of a model on a given dataset (data_loader).\n",
    "    \n",
    "    Args:\n",
    "    - model: The PyTorch model to evaluate.\n",
    "    - data_loader: The DataLoader containing the dataset.\n",
    "    - device: The device to perform calculations on (CPU or GPU).\n",
    "    \n",
    "    Returns:\n",
    "    - recall (float): The recall of the model on the given dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "            \n",
    "            # Store labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate recall using sklearn's recall_score function\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')  # 'weighted' handles class imbalance\n",
    "    return recall\n",
    "# Example usage after training or during evaluation\n",
    "test_recall = calculate_recall(trained_model, test_loader, device)\n",
    "print(f\"Test Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8a96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.7779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_f1(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate the F1 score of a model on a given dataset (data_loader).\n",
    "    \n",
    "    Args:\n",
    "    - model: The PyTorch model to evaluate.\n",
    "    - data_loader: The DataLoader containing the dataset.\n",
    "    - device: The device to perform calculations on (CPU or GPU).\n",
    "    \n",
    "    Returns:\n",
    "    - f1 (float): The F1 score of the model on the given dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "            \n",
    "            # Store labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate F1 score using sklearn's f1_score function\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  # 'weighted' handles class imbalance\n",
    "    return f1\n",
    "# Example usage after training or during evaluation\n",
    "test_f1 = calculate_f1(trained_model, test_loader, device)\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7f1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
